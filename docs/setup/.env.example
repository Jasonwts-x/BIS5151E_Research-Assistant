# ============================================================================
# Application Environment Variables Template
# ============================================================================
# Used by: Python application via src/utils/config.py (python-dotenv)
# ============================================================================
# Setup Instructions:
#   1. Copy this file to .env in project root:
#      cp docs/setup/.env.example .env
#   2. Customize values for your environment
#   3. NEVER commit .env to git (it's in .gitignore)
# ============================================================================


# ============================================================================
# LLM Configuration
# ============================================================================
# Large Language Model settings for CrewAI agents
# Model: qwen2.5:3b is balanced for quality/speed
# Alternatives: qwen2.5:7b (better quality), tinyllama:1.1b (faster)
# ============================================================================
LLM_MODEL=qwen2.5:3b
OLLAMA_HOST=http://ollama:11434
LLM_TIMEOUT=600

# ============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# ============================================================================
# Document chunking and retrieval settings
# ============================================================================

RAG_CHUNK_SIZE=350
# Size of text chunks in characters
# Larger = more context per chunk, but less precise retrieval
# Recommended: 300-500

RAG_CHUNK_OVERLAP=60
# Overlap between adjacent chunks in characters
# Prevents information loss at chunk boundaries
# Recommended: 10-20% of chunk size

RAG_TOP_K=5
# Number of most relevant chunks to retrieve
# More = more context but slower processing
# Recommended: 3-10

RAG_BACKEND=weaviate
# Vector database backend (currently only weaviate supported)


# ============================================================================
# Weaviate Vector Database Configuration
# ============================================================================
# Vector store for document embeddings and similarity search
# ============================================================================
RAG_CHUNK_OVERLAP=60
RAG_TOP_K=5
RAG_BACKEND=weaviate

# ============================================================================
# Weaviate Vector Database Configuration
# ============================================================================
# Vector store for document embeddings and similarity search
# ============================================================================

WEAVIATE_URL=http://weaviate:8080
# Weaviate API endpoint
# Docker: http://weaviate:8080
# Host: http://localhost:8080

WEAVIATE_API_KEY=
# API key for Weaviate Cloud
# Leave empty for local deployment

WEAVIATE_INDEX_NAME=ResearchDocument
# Name of the Weaviate collection/class
# Must match schema definition

WEAVIATE_TEXT_KEY=content
# Field name for document text content

WEAVIATE_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# Embedding model for text vectorization
# Options:
#   - all-MiniLM-L6-v2: Fast, 384-dim (default)
#   - all-mpnet-base-v2: Better quality, 768-dim, slower
#   - multi-qa-mpnet-base-dot-v1: Optimized for Q&A

ALLOW_SCHEMA_RESET=true
# Allow dangerous operations like schema deletion
# IMPORTANT: Set to false in production!


# ============================================================================
# ArXiv Integration Configuration
# ============================================================================
# Settings for ArXiv paper retrieval and relevance filtering
# ============================================================================

ARXIV_MIN_RELEVANCE_SCORE=0.3
# Minimum relevance score threshold (0.0-1.0)
# Papers below this score are filtered out
# Lower = more papers, possibly less relevant
# Higher = fewer papers, more relevant
# Recommended: 0.2-0.4

ARXIV_MAX_KEYWORDS=5
# Maximum number of keywords to use in ArXiv query
# Prevents overly complex queries


# ============================================================================
# API Timeout Configuration
# ============================================================================
# Request timeout settings for external services
# ============================================================================

RAG_INGESTION_TIMEOUT=120
# Timeout for ArXiv ingestion requests in seconds
# Downloading papers can take time
# Recommended: 90-180

CREWAI_EXECUTION_TIMEOUT=300
# Timeout for CrewAI workflow execution in seconds
# Multi-agent processing can be slow
# Recommended: 240-360


# ============================================================================
# PostgreSQL Database Configuration
# ============================================================================
# Database for n8n workflow persistence
# IMPORTANT: These values should match docker/.env
# ============================================================================

POSTGRES_DB=n8n
# Database name

POSTGRES_USER=n8n
# Database user

POSTGRES_PASSWORD=your_secure_password_here
# Database password
# IMPORTANT: Change this to a secure password!
# Must match POSTGRES_PASSWORD in docker/.env

POSTGRES_HOST=postgres
# PostgreSQL hostname
# Docker: postgres
# Host: localhost

POSTGRES_PORT=5432
# PostgreSQL port (default: 5432)


# ============================================================================
# File System Paths
# ============================================================================
# Directories for data storage
# ============================================================================

DATA_DIR=./data/raw
# Directory for raw documents (PDFs, TXT files)
# ArXiv papers are downloaded here

OUTPUT_DIR=./outputs
# Directory for generated outputs


# ============================================================================
# Logging Configuration
# ============================================================================
# Application logging settings
# ============================================================================

LOG_LEVEL=INFO
# Logging verbosity level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use DEBUG for development, INFO for production


# ============================================================================
# Logging Configuration
# ============================================================================
# Application logging settings
# ============================================================================

LOG_LEVEL=INFO
# Logging verbosity level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Use DEBUG for development, INFO for production


# ============================================================================
# Safety & Quality Configuration
# ============================================================================
# Guardrails and evaluation settings
# ============================================================================

GUARDRAILS_CITATION_REQUIRED=true
# Require citations in generated summaries
# Helps prevent hallucination

EVAL_FAITHFULNESS_METRIC=trulens_groundedness
# TruLens metric for faithfulness evaluation
# Requires trulens-eval package


# ============================================================================
# Development & Debug Settings
# ============================================================================
# Optional settings for development environment
# Uncomment as needed
# ============================================================================

# PYTHONPATH=/workspaces/BIS5151E_Research-Assistant
# Add project root to Python path (useful in containers)

# HF_HOME=./.hf_cache
# Hugging Face cache directory (for model downloads)

# HF_HUB_CACHE=./.hf_cache/hub
# Hugging Face Hub cache subdirectory

# SENTENCE_TRANSFORMERS_HOME=./.hf_cache
# SentenceTransformers model cache directory

# PIP_CACHE_DIR=./.pip_cache
# pip package cache directory


# ============================================================================
# End of Configuration
# ============================================================================