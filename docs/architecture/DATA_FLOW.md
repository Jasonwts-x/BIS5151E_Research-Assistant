# Data Flow Architecture

Complete data flow diagrams and request lifecycle documentation.

---

## ğŸ“Š Complete System Data Flow
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         User Layer                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚  â”‚   User     â”‚              â”‚   n8n UI     â”‚                       â”‚
â”‚  â”‚  Browser   â”‚              â”‚  Workflows   â”‚                       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                            â”‚
          â”‚ HTTP POST /research/query  â”‚ HTTP POST /rag/ingest/arxiv
          â”‚                            â”‚
          â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Gateway (Port 8000)                          â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Validate   â”‚â†’ â”‚    Route     â”‚â†’ â”‚   Respond    â”‚               â”‚
â”‚  â”‚    Input     â”‚  â”‚   Request    â”‚  â”‚   Format     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚                      â”‚
         â”‚ 1. Ingest            â”‚ 2. Query             â”‚ 3. Proxy
         â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Pipeline   â”‚   â”‚  CrewAI Service  â”‚   â”‚ Ollama Service  â”‚
â”‚  (Ingestion)    â”‚   â”‚   (Port 8100)    â”‚   â”‚ (Port 11434)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                     â”‚
         â”‚ Store chunks        â”‚ Retrieve context
         â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Weaviate Vector Database           â”‚
â”‚           (Port 8080)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ResearchDocument Collection       â”‚  â”‚
â”‚  â”‚  - Chunks                          â”‚  â”‚
â”‚  â”‚  - Embeddings (384-dim)            â”‚  â”‚
â”‚  â”‚  - Metadata                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Ingestion Flow (ArXiv)

### Step-by-Step Flow
```
1. User/n8n
   POST /rag/ingest/arxiv
   Body: {"query": "machine learning", "max_results": 3}
   â”‚
   â–¼
2. API Gateway
   - Validate request (Pydantic)
   - Call RAG pipeline
   â”‚
   â–¼
3. ArXiv Source Loader
   - Search ArXiv API
   - Download PDFs to data/arxiv/
   - Extract text with PyPDF
   â”‚
   â–¼
4. Document Processor
   - Chunk text (350 chars, 50 overlap)
   - Generate chunk metadata
   - Create chunk IDs (SHA-256 hash)
   â”‚
   â–¼
5. Embedder
   - Generate embeddings (all-MiniLM-L6-v2)
   - 384-dimensional vectors
   - Batch processing (32 chunks/batch)
   â”‚
   â–¼
6. Weaviate
   - Create ResearchDocument objects
   - Store chunks + embeddings
   - Index for search
   â”‚
   â–¼
7. API Response
   {
     "source": "arxiv",
     "documents_loaded": 3,
     "chunks_created": 142,
     "chunks_ingested": 142,
     "success": true
   }
```

### Timing Breakdown (3 papers)

| Step | Time | Percentage |
|------|------|------------|
| ArXiv search | 2s | 7% |
| PDF download | 15s | 50% |
| Text extraction | 3s | 10% |
| Chunking | 100ms | <1% |
| Embedding | 6s | 20% |
| Weaviate write | 3s | 10% |
| **Total** | **~30s** | **100%** |

---

## ğŸ” Query Flow (Research Workflow)

### Complete Research Query
```
1. User/n8n
   POST /research/query
   Body: {"query": "Explain transformers", "language": "en"}
   â”‚
   â–¼
2. API Gateway
   - Validate input (Guardrails)
   - Check query length (<10k chars)
   - Sanitize input
   â”‚
   â–¼
3. Proxy to CrewAI
   POST http://crewai:8100/run
   â”‚
   â–¼
4. CrewAI Service
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Step 4a: Context Retrieval              â”‚
   â”‚ - Embed query (384-dim)                 â”‚
   â”‚ - Hybrid search Weaviate                â”‚
   â”‚ - Top-5 chunks returned                 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Step 4b: Writer Agent                   â”‚
   â”‚ - Input: Query + Context                â”‚
   â”‚ - LLM: Ollama (qwen3:1.7b)              â”‚
   â”‚ - Output: Draft summary (~300 words)    â”‚
   â”‚ - Time: ~10s                            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Step 4c: Reviewer Agent                 â”‚
   â”‚ - Input: Draft                          â”‚
   â”‚ - Task: Improve clarity, fix grammar    â”‚
   â”‚ - LLM: Ollama (qwen3:1.7b)              â”‚
   â”‚ - Output: Reviewed summary              â”‚
   â”‚ - Time: ~5s                             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Step 4d: FactChecker Agent              â”‚
   â”‚ - Input: Reviewed summary + Context     â”‚
   â”‚ - Task: Validate claims, check citationsâ”‚
   â”‚ - LLM: Ollama (qwen3:1.7b)              â”‚
   â”‚ - Output: Final summary                 â”‚
   â”‚ - Time: ~10s                            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â–¼
5. API Gateway
   - Validate output (Guardrails)
   - Check citations, length, safety
   â”‚
   â–¼
6. Response to User
   {
     "query": "Explain transformers",
     "answer": "Transformers are...",
     "sources": [...],
     "language": "en",
     "processing_time": 28.4
   }
```

### Timing Breakdown (Single Query)

| Step | Time | Percentage |
|------|------|------------|
| Input validation | 10ms | <1% |
| Context retrieval | 500ms | 2% |
| Writer agent | 10s | 36% |
| Reviewer agent | 5s | 18% |
| FactChecker agent | 10s | 36% |
| Output validation | 20ms | <1% |
| Response formatting | 10ms | <1% |
| **Total** | **~28s** | **100%** |

---

## ğŸ”„ RAG Retrieval Flow (Detailed)
```
Query: "What are neural networks?"
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Embedder                             â”‚
â”‚ - Model: all-MiniLM-L6-v2               â”‚
â”‚ - Input: query string                   â”‚
â”‚ - Output: 384-dim vector                â”‚
â”‚ - Time: ~100ms                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Hybrid Retriever                     â”‚
â”‚                                         â”‚
â”‚ BM25 Search (Lexical):                  â”‚
â”‚ - Keyword matching                      â”‚
â”‚ - "neural", "networks"                  â”‚
â”‚ - BM25 scores: [0.8, 0.7, 0.6, ...]     â”‚
â”‚                                         â”‚
â”‚ Vector Search (Semantic):               â”‚
â”‚ - Cosine similarity                     â”‚
â”‚ - Find similar meanings                 â”‚
â”‚ - Vector scores: [0.9, 0.85, 0.8, ...]  â”‚
â”‚                                         â”‚
â”‚ Combined Score:                         â”‚
â”‚ score = 0.5*BM25 + 0.5*Vector           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Weaviate Query                       â”‚
â”‚ GraphQL:                                â”‚
â”‚ {                                       â”‚
â”‚   Get {                                 â”‚
â”‚     ResearchDocument(                   â”‚
â”‚       hybrid: {                         â”‚
â”‚         query: "neural networks"        â”‚
â”‚         vector: [0.1, 0.3, ...]         â”‚
â”‚         alpha: 0.5                      â”‚
â”‚       }                                 â”‚
â”‚       limit: 5                          â”‚
â”‚     ) {                                 â”‚
â”‚       content                           â”‚
â”‚       source                            â”‚
â”‚       _additional { score }             â”‚
â”‚     }                                   â”‚
â”‚   }                                     â”‚
â”‚ }                                       â”‚
â”‚ Time: ~300-500ms                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Results Returned                     â”‚
â”‚ [                                       â”‚
â”‚   {                                     â”‚
â”‚     "content": "Neural networks are...",â”‚
â”‚     "source": "paper1.pdf",             â”‚
â”‚     "score": 0.89                       â”‚
â”‚   },                                    â”‚
â”‚   {                                     â”‚
â”‚     "content": "A neural network...",   â”‚
â”‚     "source": "paper2.pdf",             â”‚
â”‚     "score": 0.85                       â”‚
â”‚   },                                    â”‚
â”‚   ...                                   â”‚
â”‚ ]                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Context Assembly                     â”‚
â”‚ context = """                           â”‚
â”‚ Source: paper1.pdf                      â”‚
â”‚ Neural networks are...                  â”‚
â”‚                                         â”‚
â”‚ Source: paper2.pdf                      â”‚
â”‚ A neural network...                     â”‚
â”‚ """                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
Return to CrewAI for agent processing
```

---

## ğŸ¤– Multi-Agent Collaboration Flow
```
Context Retrieved from Weaviate
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Writer Agent (Role: Research Writer)                 â”‚
â”‚                                                      â”‚
â”‚ Input:                                               â”‚
â”‚ - Query: "Explain transformers"                      â”‚
â”‚ - Context: 5 relevant chunks                         â”‚
â”‚                                                      â”‚
â”‚ Task:                                                â”‚
â”‚ "Write a concise 300-word summary on {topic}.        â”‚
â”‚  Use provided context. Include citations [1], [2]."  â”‚
â”‚                                                      â”‚
â”‚ LLM Call to Ollama:                                  â”‚
â”‚ - Model: qwen3:1.7b                                  â”‚
â”‚ - Temperature: 0.3                                   â”‚
â”‚ - Max tokens: 500                                    â”‚
â”‚                                                      â”‚
â”‚ Output:                                              â”‚
â”‚ Draft: "Transformers are neural network              â”‚
â”‚ architectures that use self-attention [1]..."        â”‚
â”‚                                                      â”‚
â”‚ Time: ~10s                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Reviewer Agent (Role: Content Reviewer)              â”‚
â”‚                                                      â”‚
â”‚ Input:                                               â”‚
â”‚ - Draft from Writer                                  â”‚
â”‚                                                      â”‚
â”‚ Task:                                                â”‚
â”‚ "Review and improve clarity and grammar.             â”‚
â”‚  Keep same meaning. Don't add new facts."            â”‚
â”‚                                                      â”‚
â”‚ LLM Call to Ollama:                                  â”‚
â”‚ - Model: qwen3:1.7b                                  â”‚
â”‚ - Temperature: 0.2 (lower for consistency)           â”‚
â”‚                                                      â”‚
â”‚ Output:                                              â”‚
â”‚ Reviewed: "Transformers are neural network           â”‚
â”‚ architectures that utilize self-attention            â”‚
â”‚ mechanisms [1]..."                                   â”‚
â”‚                                                      â”‚
â”‚ Time: ~5s                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FactChecker Agent (Role: Fact Validator)             â”‚
â”‚                                                      â”‚
â”‚ Input:                                               â”‚
â”‚ - Reviewed text from Reviewer                        â”‚
â”‚ - Original context (for verification)                â”‚
â”‚                                                      â”‚
â”‚ Task:                                                â”‚
â”‚ "Verify all claims are supported by context.         â”‚
â”‚  Check citations are consistent.                     â”‚
â”‚  Flag unsupported claims."                           â”‚
â”‚                                                      â”‚
â”‚ LLM Call to Ollama:                                  â”‚
â”‚ - Model: qwen3:1.7b                                  â”‚
â”‚ - Temperature: 0.1 (very low for accuracy)           â”‚
â”‚                                                      â”‚
â”‚ Output:                                              â”‚
â”‚ Final: "Transformers are neural network              â”‚
â”‚ architectures that utilize self-attention            â”‚
â”‚ mechanisms to process sequential data [1].           â”‚
â”‚ Unlike RNNs, they can process all tokens             â”‚
â”‚ in parallel [2]..."                                  â”‚
â”‚                                                      â”‚
â”‚ Time: ~10s                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
Return to API Gateway
```

---

## ğŸ“¤ Response Flow
```
CrewAI Returns Final Summary
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway Post-Processing             â”‚
â”‚                                         â”‚
â”‚ 1. Output Validation (Guardrails)       â”‚
â”‚    - Check citation format [1], [2]     â”‚
â”‚    - Detect hallucination markers       â”‚
â”‚    - Verify length constraints          â”‚
â”‚    - Check for harmful content          â”‚
â”‚                                         â”‚
â”‚ 2. Response Formatting                  â”‚
â”‚    - Add metadata (processing time)     â”‚
â”‚    - Include source documents           â”‚
â”‚    - Format as JSON                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HTTP Response                           â”‚
â”‚ {                                       â”‚
â”‚   "query": "Explain transformers",      â”‚
â”‚   "answer": "...",                      â”‚
â”‚   "sources": [                          â”‚
â”‚     {                                   â”‚
â”‚       "source": "paper1.pdf",           â”‚
â”‚       "chunk_index": 5,                 â”‚
â”‚       "content": "..."                  â”‚
â”‚     }                                   â”‚
â”‚   ],                                    â”‚
â”‚   "language": "en",                     â”‚
â”‚   "processing_time": 28.4               â”‚
â”‚ }                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
User/n8n receives response
```

---

## ğŸ”„ n8n Workflow Flow

### Example: Daily ArXiv Digest
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Cron Trigger                         â”‚
â”‚ - Schedule: 0 9 * * * (9 AM daily)      â”‚
â”‚ - Activates workflow                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Set Variables                        â”‚
â”‚ - topic: "machine learning"             â”‚
â”‚ - max_papers: 5                         â”‚
â”‚ - language: "en"                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. HTTP Request: Ingest                 â”‚
â”‚ POST http://api:8000/rag/ingest/arxiv   â”‚
â”‚ Body: {                                 â”‚
â”‚   "query": "{{$node.topic}}",           â”‚
â”‚   "max_results": {{$node.max_papers}}   â”‚
â”‚ }                                       â”‚
â”‚ Time: ~2 minutes                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Wait Node                            â”‚
â”‚ - Duration: 5 seconds                   â”‚
â”‚ - Ensure embeddings complete            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. HTTP Request: Query                  â”‚
â”‚ POST http://api:8000/research/query     â”‚
â”‚ Body: {                                 â”‚
â”‚   "query": "{{$node.topic}}",           â”‚
â”‚   "language": "{{$node.language}}"      â”‚
â”‚ }                                       â”‚
â”‚ Time: ~30 seconds                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Format Email                         â”‚
â”‚ - Subject: "Daily ML Digest"            â”‚
â”‚ - Body: Format answer as HTML           â”‚
â”‚ - Attach sources                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Send Email                           â”‚
â”‚ - To: user@example.com                  â”‚
â”‚ - SMTP server configured                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Error Handling Flow

### Request Validation Error
```
User Request
â”‚
â–¼
API Gateway validates
â”‚
â”œâ”€ Valid â†’ Continue
â”‚
â””â”€ Invalid
   â”‚
   â–¼
   Return 400 Bad Request
   {
     "detail": "Query too long (max 10000 chars)"
   }
```

### Service Unavailable Error
```
API Gateway
â”‚
â–¼
Call Weaviate
â”‚
â”œâ”€ Success â†’ Continue
â”‚
â””â”€ Connection Error
   â”‚
   â”œâ”€ Retry (3 attempts)
   â”‚  â”‚
   â”‚  â””â”€ Success â†’ Continue
   â”‚
   â””â”€ All retries failed
      â”‚
      â–¼
      Return 503 Service Unavailable
      {
        "detail": "Weaviate is temporarily unavailable"
      }
```

---

## ğŸ“Š Performance Optimization Points

### Bottlenecks Identified

1. **PDF Download** (50% of ingestion time)
   - Solution: Parallel downloads (future)
   - Cache downloads

2. **LLM Inference** (75% of query time)
   - Solution: GPU acceleration
   - Model quantization
   - Response caching

3. **Embedding Generation** (20% of ingestion time)
   - Solution: GPU acceleration
   - Batch processing (already implemented)

### Optimization Strategies

**Caching**:
```
Query â†’ Check cache
â”‚       â”‚
â”‚       â”œâ”€ Hit â†’ Return cached response (< 1s)
â”‚       â”‚
â”‚       â””â”€ Miss â†’ Process normally â†’ Cache result
```

**Parallel Processing**:
```
Multiple ingestion requests
â”‚
â”œâ”€ Request 1 â†’ Worker 1
â”œâ”€ Request 2 â†’ Worker 2
â”œâ”€ Request 3 â†’ Worker 3
â””â”€ Request 4 â†’ Queue
```

---

## ğŸ“š Related Documentation

- **[Architecture Overview](OVERVIEW.md)** - System design
- **[Agents](AGENTS.md)** - Multi-agent details
- **[RAG Pipeline](RAG_PIPELINE.md)** - RAG implementation

---

**[â¬… Back to Architecture](README.md)**