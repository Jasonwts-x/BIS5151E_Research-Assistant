# Architecture Documentation

System design and technical architecture of ResearchAssistantGPT.

---

## ğŸ“š Architecture Guides

| Document | Description |
|----------|-------------|
| [**System Design**](SYSTEM_DESIGN.md) | High-level architecture overview |
| [**RAG Pipeline**](RAG_PIPELINE.md) | Retrieval & generation details |
| [**Agent System**](AGENTS.md) | Multi-agent workflow |
| [**Data Flow**](DATA_FLOW.md) | Request lifecycle |

---

## ğŸ—ï¸ High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Layer                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  cURL  â”‚  Python Client  â”‚  n8n Workflows  â”‚  Swagger  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Gateway (FastAPI)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ /rag/ingest â”‚ /rag/query  â”‚ /health  â”‚ /stats   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CrewAI Service (Agent Orchestration)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Writer  â”‚  Reviewer  â”‚  FactChecker  â”‚ (Future) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                                   â”‚
     â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Pipeline      â”‚         â”‚   Ollama (LLM)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Embedder    â”‚   â”‚         â”‚  â”‚  qwen2.5:3b    â”‚  â”‚
â”‚  â”‚  Retriever   â”‚   â”‚         â”‚  â”‚  (Local Model) â”‚  â”‚
â”‚  â”‚  Chunker     â”‚   â”‚         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Weaviate (Vector Database)                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Class: ResearchDocument                           â”‚ â”‚
â”‚  â”‚  â”œâ”€ content (text)                                 â”‚ â”‚
â”‚  â”‚  â”œâ”€ source (text)                                  â”‚ â”‚
â”‚  â”‚  â”œâ”€ chunk_index (int)                              â”‚ â”‚
â”‚  â”‚  â”œâ”€ chunk_hash (text)                              â”‚ â”‚
â”‚  â”‚  â””â”€ vector (float[384])                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Request Flow

### Query Request Lifecycle
```
1. User â†’ API: POST /rag/query
   â”œâ”€ Input validation
   â”œâ”€ Query length check (<10,000 chars)
   â””â”€ Language validation (en, de, fr, es)

2. API â†’ CrewAI: Forward request
   â”œâ”€ Proxy to CrewAI service
   â””â”€ Wait for agent processing

3. CrewAI â†’ RAG Pipeline: Retrieve context
   â”œâ”€ Generate query embedding
   â”œâ”€ Hybrid search (BM25 + vector)
   â”œâ”€ Retrieve top-k chunks
   â””â”€ Format context string

4. CrewAI â†’ Ollama: Multi-agent workflow
   â”œâ”€ Writer Agent: Draft summary
   â”‚  â”œâ”€ Input: query + context
   â”‚  â”œâ”€ Output: draft with citations
   â”‚  â””â”€ Time: ~10s
   â”‚
   â”œâ”€ Reviewer Agent: Improve clarity
   â”‚  â”œâ”€ Input: draft
   â”‚  â”œâ”€ Output: improved draft
   â”‚  â””â”€ Time: ~5s
   â”‚
   â””â”€ FactChecker Agent: Validate claims
      â”œâ”€ Input: reviewed draft + context
      â”œâ”€ Output: fact-checked summary
      â””â”€ Time: ~10s

5. CrewAI â†’ API: Return final output
   â””â”€ Include source documents

6. API â†’ User: JSON response
   â”œâ”€ answer (with citations)
   â”œâ”€ source_documents
   â””â”€ metadata
```

**Total time:** 25-35 seconds per query

---

## ğŸ§© Component Details

### 1. API Gateway (FastAPI)

**Responsibilities:**
- HTTP endpoint exposure
- Request validation
- Response formatting
- Error handling
- Health checks

**Technology:** FastAPI + Uvicorn

**Key files:**
- `src/api/main.py` - Application entrypoint
- `src/api/routers/rag.py` - RAG endpoints

---

### 2. CrewAI Service

**Responsibilities:**
- Agent orchestration
- Workflow execution
- Task delegation
- Result aggregation

**Technology:** CrewAI framework

**Agents:**
- **Writer** - Drafts summaries
- **Reviewer** - Improves clarity
- **FactChecker** - Validates claims

**Key files:**
- `src/agents/crews/research_crew.py` - Crew definition
- `src/agents/runner.py` - Execution logic
- `src/agents/tasks/` - Task definitions

---

### 3. RAG Pipeline

**Responsibilities:**
- Document ingestion
- Text chunking
- Embedding generation
- Hybrid retrieval
- Context formatting

**Technology:** Haystack 2.x

**Components:**
- **Embedder** - sentence-transformers
- **Retriever** - Weaviate client
- **Chunker** - Custom implementation

**Key files:**
- `src/rag/core/pipeline.py` - Main pipeline
- `src/rag/ingestion/engine.py` - Ingestion
- `src/rag/sources/` - Data sources

---

### 4. Weaviate

**Responsibilities:**
- Vector storage
- Semantic search
- Hybrid ranking
- Deduplication

**Technology:** Weaviate 1.23.0

**Schema:**
```python
{
  "class": "ResearchDocument",
  "vectorizer": "none",  # We provide embeddings
  "properties": [
    {"name": "content", "dataType": ["text"]},
    {"name": "source", "dataType": ["text"]},
    {"name": "chunk_index", "dataType": ["int"]},
    {"name": "chunk_hash", "dataType": ["text"]}
  ]
}
```

---

### 5. Ollama

**Responsibilities:**
- LLM inference
- Text generation
- Local model hosting

**Technology:** Ollama

**Model:** qwen2.5:3b (3.5B parameters)

**Why qwen2.5:3b?**
- Small enough to run on CPU
- Good multilingual support
- Fast inference (~2s per response)
- Open-source

---

## ğŸ—„ï¸ Data Architecture

### Document Storage
```
data/
â”œâ”€â”€ raw/           # User uploads
â”‚   â”œâ”€â”€ paper1.pdf
â”‚   â””â”€â”€ paper2.txt
â”‚
â”œâ”€â”€ arxiv/         # ArXiv downloads
â”‚   â”œâ”€â”€ arxiv-2301.12345-transformer-architecture.pdf
â”‚   â””â”€â”€ arxiv-2302.67890-rag-systems.pdf
â”‚
â””â”€â”€ external/      # External datasets (unused)
```

### Vector Storage

**Weaviate stores:**
- Text chunks (500 chars each)
- Embeddings (384 dimensions)
- Metadata (source, chunk_index, hash)

**Persistence:**
- Docker volume: `weaviate_data`
- Survives container restarts
- Lost on `docker compose down -v`

### Outputs
```
outputs/
â”œâ”€â”€ 20250124_102030_machine-learning-summary.md
â”œâ”€â”€ 20250124_103045_transformer-architecture-summary.md
â””â”€â”€ ...
```

---

## ğŸ” Security Considerations

### Current State
- âŒ No authentication
- âŒ No authorization
- âŒ No rate limiting
- âš ï¸ Input validation (partial)
- âœ… Content safety checks (Guardrails)

### Future Improvements
- JWT authentication
- Role-based access control
- Rate limiting (per IP, per user)
- HTTPS/TLS
- API key management

---

## ğŸ“Š Performance Characteristics

### Latency

| Operation | Average | P95 | P99 |
|-----------|---------|-----|-----|
| Ingestion (per paper) | 5-10s | 15s | 20s |
| Query (full workflow) | 25s | 35s | 45s |
| Retrieval only | 0.5s | 1s | 2s |
| Health check | <50ms | <100ms | <200ms |

### Throughput

- **Ingestion:** ~6 papers/minute
- **Queries:** ~2 queries/minute (sequential)
- **Concurrent queries:** Limited by Ollama (1 at a time)

### Resource Usage

| Service | CPU (idle) | CPU (active) | RAM |
|---------|------------|--------------|-----|
| API | <1% | 10-20% | ~200MB |
| CrewAI | <1% | 20-30% | ~300MB |
| Weaviate | 5-10% | 20-30% | ~500MB |
| Ollama | <1% | 80-100% | ~2GB |
| PostgreSQL | <1% | 5% | ~100MB |

---

## ğŸ”® Future Architecture

### Planned Improvements

1. **Caching Layer** (Redis)
   - Cache frequent queries
   - Reduce duplicate work
   - Target: 50% cache hit rate

2. **Async Processing** (Celery)
   - Background ingestion
   - Queue management
   - Progress tracking

3. **Horizontal Scaling**
   - Multiple API instances
   - Load balancer
   - Shared cache

4. **Monitoring Stack**
   - Prometheus (metrics)
   - Grafana (dashboards)
   - Jaeger (tracing)

---

## ğŸ“– Further Reading

- [**System Design**](SYSTEM_DESIGN.md) - Detailed architecture
- [**RAG Pipeline**](RAG_PIPELINE.md) - Retrieval details
- [**Agent System**](AGENTS.md) - Multi-agent workflows
- [**Data Flow**](DATA_FLOW.md) - Request lifecycle

---

**[â¬… Back to Main README](../../README.md)**