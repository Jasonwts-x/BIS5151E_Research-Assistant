"""
Evaluation Database Models - SQLAlchemy Schema.

Defines the relational schema for persisting multi-dimensional evaluation data.
This module acts as the persistence layer for the Evaluation component, 
storing metrics generated by RAG, Agents, and Guardrails.

Architecture:
    - Centralized Record: EvaluationRecord acts as the primary anchor.
    - Specialized Metrics: One-to-one/many relationships to Performance, Quality, 
      and Guardrails tables to allow modular scaling of evaluation metrics.
    - Integration: Designed for compatibility with TruLens-style tracking.
"""
from __future__ import annotations

from datetime import datetime
from typing import List

from sqlalchemy import (
    ARRAY,
    Boolean,
    Column,
    DateTime,
    Float,
    ForeignKey,
    Integer,
    String,
    Text,
)
from sqlalchemy.orm import declarative_base, relationship

Base = declarative_base()


class EvaluationRecord(Base):
    """
    Main evaluation record acting as the central hub for all experiment data.
    
    Attributes:
        record_id: Unique identifier for the evaluation instance.
        ts: Timestamp of the execution.
        app_id: Identifier for the specific application or model version.
        input: The raw user query or prompt.
        output: The final generated response from the system.
        tags: Metadata tags for filtering and grouping experiments.
        performance: Linked performance timing data.
        quality: Linked NLP and factuality metrics.
        guardrails: Linked safety and validation results.
    """

    __tablename__ = "records"

    record_id = Column(String(255), primary_key=True)
    # Using UTC to ensure consistency across different deployment timezones
    ts = Column(DateTime, default=datetime.utcnow, nullable=False, index=True)
    app_id = Column(String(255), nullable=False)
    input = Column(Text, nullable=False) 
    output = Column(Text, nullable=False) 
    tags = Column(String(255))

    performance = relationship(
        "PerformanceMetrics", back_populates="record", cascade="all, delete-orphan"
    )
    quality = relationship(
        "QualityMetrics", back_populates="record", cascade="all, delete-orphan"
    )
    guardrails = relationship(
        "GuardrailsResults", back_populates="record", cascade="all, delete-orphan"
    )


class PerformanceMetrics(Base):
    """
    Performance timing and resource consumption metrics.
    
    Attributes:
        id: Primary key.
        record_id: Foreign key linking to the parent EvaluationRecord.
        timestamp: Creation time of the metric entry.
        total_time: End-to-end execution time.
        rag_retrieval_time: Duration of the vector search/retrieval phase.
        agent_writer_time: Execution time for the Writer Agent.
        agent_reviewer_time: Execution time for the Reviewer Agent.
        agent_factchecker_time: Execution time for the FactChecker Agent.
        llm_inference_time: Pure inference time spent by the LLM.
        guardrails_time: Overhead added by safety validation checks.
        evaluation_time: Time spent calculating these evaluation metrics.
        memory_usage_mb: Peak memory usage recorded during the run.
        token_count: Total tokens processed (prompt + completion).
        model_name: Name of the LLM used (e.g., 'llama3', 'gpt-4').
        language: Detected or specified language of the interaction.
        record: Parent EvaluationRecord instance.
    """

    __tablename__ = "performance_metrics"

    id = Column(Integer, primary_key=True, autoincrement=True)
    record_id = Column(String(255), ForeignKey("records.record_id"), nullable=False, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow, nullable=False, index=True)

    total_time = Column(Float)
    rag_retrieval_time = Column(Float)
    agent_writer_time = Column(Float)
    agent_reviewer_time = Column(Float)
    agent_factchecker_time = Column(Float)
    llm_inference_time = Column(Float)
    guardrails_time = Column(Float)
    evaluation_time = Column(Float)

    memory_usage_mb = Column(Float)
    token_count = Column(Integer)

    model_name = Column(String(100))
    language = Column(String(10))

    record = relationship("EvaluationRecord", back_populates="performance")


class QualityMetrics(Base):
    """
    Quality assessment metrics including NLP scores and factuality checks.
    
    Attributes:
        id: Primary key.
        record_id: Foreign key linking to the parent EvaluationRecord.
        timestamp: Creation time of the metric entry.
        rouge_1: Unigram overlap score.
        rouge_2: Bigram overlap score.
        rouge_l: Longest common subsequence score.
        bleu_score: Precision-based translation/generation quality score.
        semantic_similarity: Embedding-based similarity to ground truth.
        factuality_score: Normalized score representing factual accuracy.
        factuality_issues: Specific discrepancies found by the FactChecker.
        citation_count: Total number of source citations generated.
        citation_quality: Score reflecting citation accuracy/relevance.
        answer_length: Character count of the generated response.
        sentence_count: Number of sentences in the response.
        consistency_runs: Number of iterations used for self-consistency checks.
        consistency_std_dev: Variance between multiple generation attempts.
        consistency_passed: Flag indicating if the response met consistency thresholds.
        paraphrase_variations: Count of paraphrased inputs tested.
        paraphrase_max_diff: Maximum score variance across paraphrased inputs.
        paraphrase_stable: Flag indicating if output is robust to input phrasing.
        record: Parent EvaluationRecord instance.
    """

    __tablename__ = "quality_metrics"

    id = Column(Integer, primary_key=True, autoincrement=True)
    record_id = Column(String(255), ForeignKey("records.record_id"), nullable=False, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow, nullable=False, index=True)

    rouge_1 = Column(Float)
    rouge_2 = Column(Float)
    rouge_l = Column(Float)

    bleu_score = Column(Float)
    semantic_similarity = Column(Float)

    factuality_score = Column(Float)
    # ARRAY used to store multiple specific issues for granular debugging
    factuality_issues = Column(ARRAY(Text)) 

    citation_count = Column(Integer)
    citation_quality = Column(Float)

    answer_length = Column(Integer)
    sentence_count = Column(Integer)

    consistency_runs = Column(Integer)
    consistency_std_dev = Column(Float)
    consistency_passed = Column(Boolean)

    paraphrase_variations = Column(Integer)
    paraphrase_max_diff = Column(Float)
    paraphrase_stable = Column(Boolean)

    record = relationship("EvaluationRecord", back_populates="quality")


class EvaluationScores(Base):
    """
    Aggregated high-level scores for rapid dashboarding and comparison.
    
    Attributes:
        id: Primary key.
        record_id: Foreign key linking to the parent EvaluationRecord.
        timestamp: Creation time of the score entry.
        overall_score: Weighted average of all evaluation dimensions.
        groundedness: Degree to which the answer is supported by context.
        answer_relevance: How well the answer addresses the user query.
        context_relevance: How useful the retrieved context was for the query.
        citation_quality: Re-persisted citation score for flat querying.
        record: Parent EvaluationRecord instance.
    """
    __tablename__ = "evaluation_scores"
    
    id = Column(Integer, primary_key=True, autoincrement=True)
    record_id = Column(String(255), ForeignKey("records.record_id"), nullable=False, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow, nullable=False)
    
    overall_score = Column(Float)
    groundedness = Column(Float)
    answer_relevance = Column(Float)
    context_relevance = Column(Float)
    citation_quality = Column(Float)
    
    record = relationship("EvaluationRecord", backref="scores")


class GuardrailsResults(Base):
    """
    Results from safety, privacy, and policy validation layers.
    
    Attributes:
        id: Primary key.
        record_id: Foreign key linking to the parent EvaluationRecord.
        timestamp: Creation time of the validation entry.
        input_passed: Whether the user query cleared safety checks.
        output_passed: Whether the generated response cleared safety checks.
        overall_passed: Global safety status for the interaction.
        jailbreak_detected: Boolean flag for malicious prompt injection.
        pii_detected: Boolean flag for sensitive personal data leaks.
        off_topic_detected: Boolean flag for query relevance filtering.
        citation_issues: Flag for missing or malformed citations.
        hallucination_markers: Flag for detected non-factual patterns.
        length_violation: Flag for responses exceeding character limits.
        harmful_content: Flag for toxic or prohibited content generation.
        violations: Detailed list of specific policy violations.
        warnings: Non-blocking alerts triggered during validation.
        record: Parent EvaluationRecord instance.
    """

    __tablename__ = "guardrails_results"

    id = Column(Integer, primary_key=True, autoincrement=True)
    record_id = Column(String(255), ForeignKey("records.record_id"), nullable=False, index=True)
    timestamp = Column(DateTime, default=datetime.utcnow, nullable=False, index=True)

    input_passed = Column(Boolean, nullable=False)
    output_passed = Column(Boolean, nullable=False)
    overall_passed = Column(Boolean, nullable=False)

    jailbreak_detected = Column(Boolean, default=False)
    pii_detected = Column(Boolean, default=False)
    off_topic_detected = Column(Boolean, default=False)

    citation_issues = Column(Boolean, default=False)
    hallucination_markers = Column(Boolean, default=False)
    length_violation = Column(Boolean, default=False)
    harmful_content = Column(Boolean, default=False)

    # Violations are stored as a list to capture multiple concurrent policy failures
    violations = Column(ARRAY(Text))
    warnings = Column(ARRAY(Text))

    record = relationship("EvaluationRecord", back_populates="guardrails")