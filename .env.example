# Environment configuration template for ResearchAssistantGPT

# .env.example
LLM_MODEL=llama3
OLLAMA_HOST=http://localhost:11434

# Retrieval
RAG_CHUNK_SIZE=350
RAG_CHUNK_OVERLAP=60
RAG_TOP_K=5

# (Future) APIs
# OPENAI_API_KEY=
# TRULENS_API_KEY=
# GUARDRAILS_API_KEY=