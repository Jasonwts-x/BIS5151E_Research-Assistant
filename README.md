# ResearchAssistantGPT

[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-Academic-green.svg)]()

> AI-powered research assistant with RAG and multi-agent workflows for academic literature review

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Course Context](#-course-context)
- [Project Objectives](#-project-objectives)
- [Technical Stack](#%EF%B8%8F-technical-stack)
- [Architecture](#%EF%B8%8F-architecture)
- [Folder Structure](#-folder-structure)
- [Quick Start](#-quick-start)
- [Documentation](#-documentation)
- [Development](#%EF%B8%8F-development)
- [Usage Examples](#-usage-examples)
- [Team](#-team)
- [License](#-license)

---

## ğŸ¯ Overview

ResearchAssistantGPT is a **RAG-based research assistant** that generates **cited summaries** from academic papers using multi-agent AI workflows. The system combines retrieval-augmented generation with fact-checking agents to ensure accuracy and proper citation.

**Key Features**:
- ğŸ“š **Automatic literature ingestion** from ArXiv and local files
- ğŸ” **Hybrid retrieval** using Weaviate vector database
- ğŸ¤– **Multi-agent workflow** (Writer â†’ Reviewer â†’ FactChecker)
- âœ… **Citation validation** and fact-checking
- ğŸŒ **Multilingual support** (English, German, French, Spanish)
- ğŸ”’ **Privacy-preserving** (runs entirely on local infrastructure)

---

## ğŸ“ Course Context

**Course**: BIS5151 â€“ Generative Artificial Intelligence  
**Institution**: Hochschule Pforzheim  
**Program**: Master of Information Systems  
**Semester**: Winter 2025/26  
**Instructor**: Prof. Dr. Manuel Fritz, MBA

This project demonstrates practical application of:
- Retrieval-Augmented Generation (RAG)
- Multi-agent AI systems
- LLM orchestration and governance
- AI evaluation frameworks

---

## ğŸ¯ Project Objectives

### Core Objectives
1. **Literature Retrieval**: Fetch and index academic papers from ArXiv and local sources
2. **Context-Aware Summarization**: Generate 300-word summaries grounded in source documents
3. **Fact Verification**: Validate all claims against retrieved sources
4. **Citation Discipline**: Ensure proper attribution with [1], [2], etc. markers
5. **Quality Assurance**: Implement evaluation frameworks (TruLens, Guardrails AI)

### Learning Goals
- Hands-on experience with modern RAG architectures
- Understanding of agent-based AI systems (CrewAI)
- Practical knowledge of LLM evaluation and governance
- Workflow orchestration with n8n

---

## ğŸ› ï¸ Technical Stack

### Core Technologies

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Language** | Python 3.11 | Core development |
| **API Framework** | FastAPI + Uvicorn | REST API gateway |
| **RAG Framework** | Haystack 2.x | Document processing & retrieval |
| **Vector Database** | Weaviate | Hybrid search (lexical + semantic) |
| **LLM Runtime** | Ollama (qwen2.5:3b) | Local inference |
| **Agent Framework** | CrewAI 1.3.0 | Multi-agent orchestration |
| **Workflow Engine** | n8n | End-to-end automation |
| **Database** | PostgreSQL 15 | n8n workflow storage |
| **Embeddings** | Sentence-Transformers | Document vectorization |
| **Evaluation** | TruLens + Guardrails AI | Quality assurance |
| **Containerization** | Docker + Docker Compose | Service orchestration |

### Python Libraries
```python
crewai==1.3.0                # Multi-agent framework
haystack-ai==2.18.1          # RAG pipeline
weaviate-haystack==6.3.0     # Weaviate integration
langchain-ollama==1.0.1      # LLM integration
fastapi                      # Web framework
httpx                        # Async HTTP client
arxiv==2.1.0                # ArXiv paper fetching
```

---

## ğŸ—ï¸ Architecture

### System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        n8n Orchestrator                     â”‚
â”‚                 Workflow Automation (Port 5678)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway    â”‚              â”‚                    â”‚
â”‚   (FastAPI)      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   CrewAI Service   â”‚
â”‚   Port 8000      â”‚  Proxy       â”‚   Port 8100        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                    â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚            â”‚                      â”‚            â”‚
    â”‚  RAG       â”‚                      â”‚  Multi-    â”‚
    â”‚  Pipeline  â”‚                      â”‚  Agent     â”‚
    â”‚            â”‚                      â”‚  Workflow  â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Weaviate   â”‚        â”‚   Ollama     â”‚            â”‚
â”‚  â”‚  Port 8080  â”‚        â”‚  Port 11434  â”‚            â”‚
â”‚  â”‚             â”‚        â”‚              â”‚            â”‚
â”‚  â”‚ â€¢ Hybrid    â”‚        â”‚ â€¢ LLM        â”‚            â”‚
â”‚  â”‚   Search    â”‚        â”‚   Inference  â”‚            â”‚
â”‚  â”‚ â€¢ Vector DB â”‚        â”‚ â€¢ qwen2.5:3b â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ PostgreSQL  â”‚                                    â”‚
â”‚  â”‚  Port 5432  â”‚                                    â”‚
â”‚  â”‚             â”‚                                    â”‚
â”‚  â”‚ â€¢ n8n DB    â”‚                                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Request Flow
```
1. User â†’ n8n: Trigger workflow with research topic
2. n8n â†’ API: POST /rag/query {"query": "...", "language": "en"}
3. API â†’ CrewAI: POST /crew/run (proxy request)
4. CrewAI â†’ Weaviate: Retrieve top-k relevant chunks
5. CrewAI â†’ Ollama: Run multi-agent workflow:
   â”œâ”€ Writer: Draft summary from context
   â”œâ”€ Reviewer: Improve clarity
   â””â”€ FactChecker: Verify claims against sources
6. CrewAI â†’ API: Return fact-checked summary
7. API â†’ n8n: Return final result
8. n8n â†’ User: Deliver summary (email, webhook, etc.)
```

---

## ğŸ“ Folder Structure
```
BIS5151E_Research-Assistant/
â”œâ”€â”€ .devcontainer/              # VS Code DevContainer configuration
â”‚   â”œâ”€â”€ Dockerfile              # Multi-stage build (dev, api, crewai)
â”‚   â””â”€â”€ devcontainer.json       # Container settings
â”‚
â”œâ”€â”€ .github/                    # GitHub configuration
â”‚   â”œâ”€â”€ workflows/              
â”‚   â”‚   â””â”€â”€ ci.yml              # CI/CD pipeline (pytest, ruff, black)
â”‚   â””â”€â”€ CODEOWNERS              # Code ownership
â”‚
â”œâ”€â”€ configs/                    # Application configuration
â”‚   â””â”€â”€ app.yaml                # Main config (LLM, RAG, Weaviate settings)
â”‚
â”œâ”€â”€ data/                       # Data storage (gitignored except .gitkeep)
â”‚   â”œâ”€â”€ raw/                    # Source documents (PDFs, TXT)
â”‚   â”œâ”€â”€ processed/              # Processed chunks
â”‚   â””â”€â”€ external/               # External datasets
â”‚
â”œâ”€â”€ docker/                     # Docker configuration
â”‚   â”œâ”€â”€ docker-compose.yml      # Main service definitions
â”‚   â”œâ”€â”€ docker-compose.nvidia.yml # GPU support (NVIDIA)
â”‚   â”œâ”€â”€ docker-compose.amd.yml  # GPU support (AMD)
â”‚   â”œâ”€â”€ .env.example            # Docker secrets template
â”‚   â””â”€â”€ workflows/              # n8n workflow files
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ setup/                  # Installation guides
â”‚   â”œâ”€â”€ api/                    # API documentation
â”‚   â”œâ”€â”€ architecture/           # Design documents
â”‚   â”œâ”€â”€ examples/               # Usage examples
â”‚   â””â”€â”€ troubleshooting/        # Common issues
â”‚
â”œâ”€â”€ outputs/                    # Generated summaries (gitignored)
â”‚
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ admin/                  # Administrative tasks
â”‚   â”‚   â”œâ”€â”€ health_check.py     # Service health verification
â”‚   â”‚   â”œâ”€â”€ backup_data.sh      # Backup persistent data
â”‚   â”‚   â””â”€â”€ cleanup_volumes.sh  # Docker cleanup
â”‚   â”œâ”€â”€ dev/                    # Development helpers
â”‚   â”‚   â”œâ”€â”€ start_services.sh   # Start all services
â”‚   â”‚   â”œâ”€â”€ stop_services.sh    # Stop all services
â”‚   â”‚   â””â”€â”€ restart_service.sh  # Restart specific service
â”‚   â”œâ”€â”€ manual/                 # Manual testing scripts
â”‚   â””â”€â”€ setup/                  # Installation helpers
â”‚       â”œâ”€â”€ verify_gpu.sh       # GPU detection
â”‚       â””â”€â”€ install_gpu_support_linux.sh
â”‚
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ agents/                 # CrewAI multi-agent system
â”‚   â”‚   â”œâ”€â”€ api/                # CrewAI service (port 8100)
â”‚   â”‚   â”œâ”€â”€ config/             # Agent/task YAML configs
â”‚   â”‚   â”œâ”€â”€ crews/              # Crew compositions
â”‚   â”‚   â”œâ”€â”€ roles/              # Agent definitions
â”‚   â”‚   â”œâ”€â”€ tasks/              # Task definitions
â”‚   â”‚   â”œâ”€â”€ tools/              # Custom tools
â”‚   â”‚   â””â”€â”€ runner.py           # Main execution logic
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                    # Main API gateway (port 8000)
â”‚   â”‚   â”œâ”€â”€ routers/            # Endpoint implementations
â”‚   â”‚   â”œâ”€â”€ schemas/            # Pydantic models
â”‚   â”‚   â”œâ”€â”€ dependencies.py     # Dependency injection
â”‚   â”‚   â”œâ”€â”€ errors.py           # Error handling
â”‚   â”‚   â”œâ”€â”€ openapi.py          # API documentation config
â”‚   â”‚   â””â”€â”€ server.py           # FastAPI app
â”‚   â”‚
â”‚   â”œâ”€â”€ eval/                   # Evaluation & quality assurance
â”‚   â”‚   â”œâ”€â”€ guardrails.py       # Safety checks
â”‚   â”‚   â””â”€â”€ trulens.py          # Monitoring
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/                    # RAG pipeline
â”‚   â”‚   â”œâ”€â”€ core/               # Core infrastructure
â”‚   â”‚   â”‚   â”œâ”€â”€ pipeline.py     # Main RAG pipeline
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.py       # Weaviate schema management
â”‚   â”‚   â”‚   â””â”€â”€ service.py      # RAG service layer
â”‚   â”‚   â”œâ”€â”€ ingestion/          # Document processing
â”‚   â”‚   â”‚   â”œâ”€â”€ engine.py       # Ingestion orchestration
â”‚   â”‚   â”‚   â””â”€â”€ processor.py    # Chunking & ID generation
â”‚   â”‚   â””â”€â”€ sources/            # Data sources
â”‚   â”‚       â”œâ”€â”€ base.py         # Abstract source
â”‚   â”‚       â”œâ”€â”€ local.py        # Local file source
â”‚   â”‚       â””â”€â”€ arxiv.py        # ArXiv source
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Shared utilities
â”‚       â””â”€â”€ config.py           # Configuration management
â”‚
â”œâ”€â”€ tests/                      # Test suite
â”‚   â”œâ”€â”€ conftest.py             # Shared fixtures
â”‚   â”œâ”€â”€ unit/                   # Unit tests
â”‚   â”‚   â”œâ”€â”€ test_rag/
â”‚   â”‚   â”œâ”€â”€ test_agents/
â”‚   â”‚   â””â”€â”€ test_api/
â”‚   â”œâ”€â”€ integration/            # Integration tests
â”‚   â””â”€â”€ fixtures/               # Test data
â”‚
â”œâ”€â”€ .env.example                # Application environment template
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ .ruff.toml                  # Ruff linter config
â”œâ”€â”€ CONTRIBUTING.md             # Contribution guidelines
â”œâ”€â”€ README.md                   # This file
â””â”€â”€ requirements.txt            # Python dependencies
```

---

## ğŸš€ Quick Start

### Prerequisites
- **Docker Desktop** (with 16GB+ RAM allocated)
- **Git**
- **20GB free disk space**

### Installation (5 steps)
```bash
# 1. Clone repository
git clone https://github.com/Jasonwts-x/BIS5151E_Research-Assistant.git
cd BIS5151E_Research-Assistant

# 2. Configure environment
cp .env.example .env
cp docker/.env.example docker/.env
# Edit docker/.env: Set POSTGRES_PASSWORD and N8N_ENCRYPTION_KEY

# 3. Start services (CPU mode)
docker compose -f docker/docker-compose.yml up -d

# 4. Verify installation
python scripts/admin/health_check.py

# 5. Ingest sample data
curl -X POST http://localhost:8000/rag/ingest/arxiv \
  -H "Content-Type: application/json" \
  -d '{"query": "machine learning", "max_results": 3}'
```

### First Query
```bash
curl -X POST http://localhost:8000/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is machine learning?",
    "language": "en"
  }'
```

**See full installation guide**: [docs/setup/INSTALLATION.md](docs/setup/INSTALLATION.md)

---

## ğŸ“š Documentation

- **[Installation Guide](docs/setup/INSTALLATION.md)** - Step-by-step setup
- **[API Documentation](docs/api/README.md)** - Endpoint reference
- **[Architecture](docs/architecture/README.md)** - System design
- **[Troubleshooting](docs/troubleshooting/README.md)** - Common issues
- **[Examples](docs/examples/README.md)** - Usage examples

**Quick Links**:
- API Docs (Swagger): http://localhost:8000/docs
- n8n UI: http://localhost:5678
- Weaviate Console: http://localhost:8080/v1/meta

---

## ğŸ› ï¸ Development

### Open in DevContainer
```bash
# VS Code will detect .devcontainer/devcontainer.json
# Click "Reopen in Container"
```

### Run Tests
```bash
# All tests
pytest tests/ -v

# Unit tests only (fast)
pytest tests/unit/ -v

# Integration tests (requires services)
pytest tests/integration/ -v

# With coverage
pytest tests/ --cov=src --cov-report=html
```

### Code Quality
```bash
# Format code
black src tests

# Lint
ruff check src tests --fix

# Type check
mypy src
```

### Commit Standards

We use **conventional commits**:
```
<feature>(<category>): <description>

Features: chore, docs, feat, fix, refactor, style, test
Categories: agents, api, docker, docs, rag, refactor, tests
Example: feat(agents): add translator agent for multilingual support
```

---

## ğŸ“Š Usage Examples

### API
```bash
# Ingest ArXiv papers
curl -X POST http://localhost:8000/rag/ingest/arxiv \
  -H "Content-Type: application/json" \
  -d '{"query": "retrieval augmented generation", "max_results": 5}'

# Query with multi-agent processing
curl -X POST http://localhost:8000/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What is RAG?",
    "language": "en"
  }'

# Get index statistics
curl http://localhost:8000/rag/stats
```

### CLI
```bash
# Ingest local files
python -m src.rag.cli ingest-local --pattern "*.pdf"

# Fetch from ArXiv
python -m src.rag.cli ingest-arxiv "neural networks" --max-results 10

# Test retrieval
python -m src.rag.cli query "What is deep learning?" --top-k 5

# Reset index
python -m src.rag.cli reset-index --yes
```

---

## ğŸ“Š Evaluation & Monitoring

ResearchAssistantGPT includes comprehensive evaluation and monitoring:

### Evaluation Dashboard

Access the interactive dashboard at **http://localhost:8501** to view:
- TruLens quality metrics (groundedness, relevance)
- Guardrails validation results
- Performance timing breakdown
- ROUGE/BLEU quality scores

### Evaluation API

Query evaluation metrics programmatically:
```bash
# Get evaluation leaderboard
curl http://localhost:8502/metrics/leaderboard

# Get specific evaluation record
curl http://localhost:8502/metrics/record/{record_id}
```

### Evaluation in Query Responses

All query responses automatically include evaluation metrics:
```json
{
  "topic": "What is RAG?",
  "answer": "Retrieval-Augmented Generation...",
  "evaluation": {
    "trulens": {
      "groundedness": 0.85,
      "answer_relevance": 0.78,
      "context_relevance": 0.82
    },
    "guardrails": {
      "input_passed": true,
      "output_passed": true
    },
    "performance": {
      "total_time": 45.2,
      "rag_retrieval": 2.1,
      "crew_execution": 42.5
    }
  }
}
```

See [Evaluation Documentation](docs/evaluation/README.md) for details.

---

## ğŸ‘¥ Team

**Project Group**: ResearchAssistantGPT

- **Jason Waschtschenko** (GitHub: [@Jasonwts-x](https://github.com/Jasonwts-x))
- **Karim Epple**
- **Dilsat Bekil**
- **Rigon Rexha**
- **Eren Kaya**

---

## ğŸ“ License

This project is for **educational use** within the Master of Information Systems program at Hochschule Pforzheim.

All AI models and datasets used comply with open-source or institutional usage rights.

---

## ğŸ™ Acknowledgments

- **Prof. Dr. Manuel Fritz, MBA** - Course instructor
- **Anthropic** - Claude AI assistance in development
- **Hochschule Pforzheim** - Academic support

---

**[â¬† Back to top](#researchassistantgpt)**

---