llm:
  provider: "ollama"
  model: "llama3"
  host: "http://host.docker.internal:11434"
rag:
  chunk_size: 350
  chunk_overlap: 60
  top_k: 5
guardrails:
  citation_required: true
eval:
  faithfulness_metric: "trulens_groundedness"
